{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pybullet as p\n",
    "import pybullet_data\n",
    "import os\n",
    "import time\n",
    "import roboticstoolbox as rtb\n",
    "import cv2\n",
    "import spatialmath as sm\n",
    "from spatialmath.base import delta2tr, tr2delta\n",
    "# can use this to apply angular rotations to coordinate frames\n",
    "from scipy.spatial.transform import Rotation as Rot\n",
    "\n",
    "# camera (don't change these settings)\n",
    "camera_width = 512  # image width\n",
    "camera_height = 512  # image height\n",
    "camera_fov = 120  # field of view of camera\n",
    "camera_focal_depth = 0.5*camera_height/np.tan(0.5*np.pi/180*camera_fov)\n",
    "# focal depth in pixel space\n",
    "camera_aspect = camera_width/camera_height  # aspect ratio\n",
    "camera_near = 0.02  # near clipping plane in meters, do not set non-zero\n",
    "camera_far = 100  # far clipping plane in meters\n",
    "\n",
    "\n",
    "# control objectives (if you wish, you can play with these values for fun)\n",
    "object_location_desired = np.array([camera_width/2, camera_height/2])\n",
    "# center the object to middle of image\n",
    "K_p_x = 0.1  # Proportional control gain for translation\n",
    "K_p_Omega = 0.02  # Proportional control gain for rotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robot with Camera Class\n",
    "class eye_in_hand_robot:\n",
    "    def get_ee_position(self):\n",
    "        '''\n",
    "        Function to return the end-effector of the link. This is the very tip of the robot at the end of the jaws.\n",
    "        '''\n",
    "        endEffectorIndex = self.numActiveJoints\n",
    "        endEffectorState = p.getLinkState(self.robot_id, endEffectorIndex)\n",
    "        endEffectorPos = np.array(endEffectorState[0])\n",
    "        endEffectorOrn = np.array(p.getMatrixFromQuaternion(\n",
    "            endEffectorState[1])).reshape(3, 3)\n",
    "\n",
    "        # add an offset to get past the forceps\n",
    "        endEffectorPos += self.camera_offset*endEffectorOrn[:, 2]\n",
    "        return endEffectorPos, endEffectorOrn\n",
    "\n",
    "    def get_current_joint_angles(self):\n",
    "        # Get the current joint angles\n",
    "        joint_angles = np.zeros(self.numActiveJoints)\n",
    "        for i in range(self.numActiveJoints):\n",
    "            joint_state = p.getJointState(\n",
    "                self.robot_id, self._active_joint_indices[i])\n",
    "            joint_angles[i] = joint_state[0]\n",
    "        return joint_angles\n",
    "\n",
    "    def get_jacobian_at_current_position(self):\n",
    "        # Returns the Robot Jacobian of the last active link\n",
    "        mpos, mvel, mtorq = self.get_active_joint_states()\n",
    "        zero_vec = [0.0]*len(mpos)\n",
    "        linearJacobian, angularJacobian = p.calculateJacobian(self.robot_id,\n",
    "                                                              self.numActiveJoints,\n",
    "                                                              [0, 0, self.camera_offset],\n",
    "                                                              mpos,\n",
    "                                                              zero_vec,\n",
    "                                                              zero_vec)\n",
    "        # only return the active joint's jacobians\n",
    "        Jacobian = np.vstack((linearJacobian, angularJacobian))\n",
    "        return Jacobian[:, :self.numActiveJoints]\n",
    "\n",
    "    def getJointStates(self):\n",
    "        joint_states = p.getJointStates(\n",
    "            self.robot_id, range(self._numLinkJoints))\n",
    "        joint_positions = [state[0] for state in joint_states]\n",
    "        joint_velocities = [state[1] for state in joint_states]\n",
    "        joint_torques = [state[3] for state in joint_states]\n",
    "        return joint_positions, joint_velocities, joint_torques\n",
    "\n",
    "    def set_joint_position(self, desireJointPositions, kp=1.0, kv=0.3):\n",
    "        zero_vec = [0.0] * self._numLinkJoints\n",
    "        allJointPositionObjectives = [0.0]*self._numLinkJoints\n",
    "        for i in range(desireJointPositions.shape[0]):\n",
    "            idx = self._active_joint_indices[i]\n",
    "            allJointPositionObjectives[idx] = desireJointPositions[i]\n",
    "\n",
    "        p.setJointMotorControlArray(self.robot_id,\n",
    "                                    range(self._numLinkJoints),\n",
    "                                    p.POSITION_CONTROL,\n",
    "                                    targetPositions=allJointPositionObjectives,\n",
    "                                    targetVelocities=zero_vec,\n",
    "                                    positionGains=[kp] * self._numLinkJoints,\n",
    "                                    velocityGains=[kv] * self._numLinkJoints)\n",
    "\n",
    "    def get_active_joint_states(self):\n",
    "        joint_states = p.getJointStates(\n",
    "            self.robot_id, range(self._numLinkJoints))\n",
    "        joint_infos = [p.getJointInfo(self.robot_id, i)\n",
    "                       for i in range(self._numLinkJoints)]\n",
    "        joint_states = [j for j, i in zip(\n",
    "            joint_states, joint_infos) if i[3] > -1]\n",
    "        joint_positions = [state[0] for state in joint_states]\n",
    "        joint_velocities = [state[1] for state in joint_states]\n",
    "        joint_torques = [state[3] for state in joint_states]\n",
    "        return joint_positions, joint_velocities, joint_torques\n",
    "\n",
    "    def __init__(self, robot_id, initialJointPos):\n",
    "        self.robot_id = robot_id\n",
    "        self.eeFrameId = []\n",
    "        self.camera_offset = 0.1  # offset camera in z direction to avoid grippers\n",
    "        # Get the joint info\n",
    "        self._numLinkJoints = p.getNumJoints(\n",
    "            self.robot_id)  # includes passive joint\n",
    "        jointInfo = [p.getJointInfo(self.robot_id, i)\n",
    "                     for i in range(self._numLinkJoints)]\n",
    "\n",
    "        # Get joint locations (some joints are passive)\n",
    "        self._active_joint_indices = []\n",
    "        for i in range(self._numLinkJoints):\n",
    "            if jointInfo[i][2] == p.JOINT_REVOLUTE:\n",
    "                self._active_joint_indices.append(jointInfo[i][0])\n",
    "        # exact number of active joints\n",
    "        self.numActiveJoints = len(self._active_joint_indices)\n",
    "\n",
    "        # reset joints\n",
    "        for i in range(self._numLinkJoints):\n",
    "            p.resetJointState(self.robot_id, i, initialJointPos[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxillary funcitons \n",
    "\n",
    "def operate_ee(robot,cmd):\n",
    "    '''cmd = 0 to close, 1 to open'''\n",
    "    # assert(cmd==0 or cmd==1)\n",
    "    for I in range(50):\n",
    "        p.setJointMotorControlArray(robot.robot_id, [9,10], p.POSITION_CONTROL, targetPositions=[cmd,cmd])\n",
    "        p.stepSimulation()\n",
    "        # global out\n",
    "        # width, height, rgbImg, depthImg, segImg = p.getCameraImage(640, 480)\n",
    "        # rgbImg = np.reshape(rgbImg, (height, width, 4))\n",
    "        # out.write(cv2.cvtColor(rgbImg, cv2.COLOR_RGBA2BGR))\n",
    "\n",
    "def move_ee(robot,T):\n",
    "    \n",
    "    ee_position = np.array(T)[0:3,3] \n",
    "    ee_orientation = sm.base.r2q(np.array(T)[0:3,0:3])\n",
    "    pos_err = np.linalg.norm(robot.get_ee_position()[0]-ee_position)\n",
    "    count=0\n",
    "    while (pos_err> 0.01):\n",
    "        j = np.array(p.calculateInverseKinematics(robot.robot_id,11,ee_position, ee_orientation))\n",
    "        for i in range(len(j)):\n",
    "            p.setJointMotorControl2(robot.robot_id, i, p.POSITION_CONTROL, j[i]) \n",
    "        p.stepSimulation()\n",
    "        # global out\n",
    "        # width, height, rgbImg, depthImg, segImg = p.getCameraImage(640, 480)\n",
    "        # rgbImg = np.reshape(rgbImg, (height, width, 4))\n",
    "        # out.write(cv2.cvtColor(rgbImg, cv2.COLOR_RGBA2BGR))\n",
    "        time.sleep(1/240)\n",
    "        pos_err = np.linalg.norm(robot.get_ee_position()[0]-ee_position)\n",
    "        count=count+1\n",
    "        if count>240:            \n",
    "            break\n",
    "\n",
    "def move_ee_timed(robot,T,t):\n",
    "    ee_position = np.array(T)[0:3,3] \n",
    "    ee_orientation = sm.base.r2q(np.array(T)[0:3,0:3])\n",
    "    \n",
    "    for _ in range(t*240):\n",
    "\n",
    "        j = np.array(p.calculateInverseKinematics(robot.robot_id,11,ee_position, ee_orientation))\n",
    "        for i in range(len(j)):\n",
    "            p.setJointMotorControl2(robot.robot_id, i, p.POSITION_CONTROL, j[i]) \n",
    "        p.stepSimulation()\n",
    "        # global out\n",
    "        # width, height, rgbImg, depthImg, segImg = p.getCameraImage(640, 480)\n",
    "        # rgbImg = np.reshape(rgbImg, (height, width, 4))\n",
    "        # out.write(cv2.cvtColor(rgbImg, cv2.COLOR_RGBA2BGR))\n",
    "        time.sleep(1/240)\n",
    "           \n",
    "\n",
    "def move_traj_ee(robot,trajectory):\n",
    "    for traj in trajectory:\n",
    "        move_ee(robot,traj)\n",
    "\n",
    "def manipulability_measure(jacobian):\n",
    "    \"\"\"\n",
    "    Calculate the manipulability measure of a robot arm given its Jacobian matrix.\n",
    "    :param jacobian: Jacobian matrix of the robot arm\n",
    "    :return: manipulability measure\n",
    "    \"\"\"\n",
    "    u, s, vh = np.linalg.svd(jacobian)\n",
    "    return np.product(s)\n",
    "\n",
    "def product_of_MM(robot1,robot2):\n",
    "    return manipulability_measure(robot1.get_jacobian_at_current_position())*manipulability_measure(robot2.get_jacobian_at_current_position())\n",
    "\n",
    "def to_optimise(z):\n",
    "    global robot1,robot2\n",
    "    T3 = sm.SE3.Rt(np.array(sm.SO3.RPY([90,0,90],unit= 'deg')),np.array([0.5,0.5,z]))\n",
    "    T5 = sm.SE3.Rt(np.array(sm.SO3.RPY([0,-90,0],unit= 'deg')),np.array([0.5,0.5,z]))\n",
    "    move_ee(robot1,T3)\n",
    "    move_ee(robot2,T5)\n",
    "    return -product_of_MM(robot1,robot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the connection to the physics server\n",
    "\n",
    "def pybenv():\n",
    "    global robot1, robot2, box, out\n",
    "    try:\n",
    "        cv2.destroyAllWindows()\n",
    "        p.disconnect()\n",
    "    except:\n",
    "        pass\n",
    "    physicsClient = p.connect(p.GUI)  # (p.DIRECT)\n",
    "    # time_step = 0.001\n",
    "    p.resetSimulation()\n",
    "    # p.setTimeStep(time_step)\n",
    "    p.setGravity(0, 0, -9.8)\n",
    "\n",
    "    # Set the path to the URDF files included with PyBullet\n",
    "    p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "\n",
    "    # load a plane URDF\n",
    "    p.loadURDF('plane.urdf')\n",
    "    \n",
    "    p.resetDebugVisualizerCamera(\n",
    "        cameraDistance=1, cameraYaw=30, cameraPitch=-52, cameraTargetPosition=[0, 0, .5])\n",
    "    \n",
    "    # Load robot 1\n",
    "    pandaUid1 = p.loadURDF(os.path.join(\n",
    "        pybullet_data.getDataPath(), \"franka_panda\\\\panda.urdf\"), useFixedBase=True)\n",
    "    p.resetBasePositionAndOrientation(pandaUid1, [0, 0, 0], [0, 0, 0, 1])\n",
    "    initialJointPosition = [0, -np.pi/4, np.pi/4, -\n",
    "                            np.pi/4, np.pi/4, np.pi/4, np.pi/4, 0, 0, 0, 0, 0]\n",
    "    robot1 = eye_in_hand_robot(pandaUid1, initialJointPosition)\n",
    "\n",
    "    # Load robot 2\n",
    "    pandaUid2 = p.loadURDF(os.path.join(\n",
    "        pybullet_data.getDataPath(), \"franka_panda\\\\panda.urdf\"), useFixedBase=True)\n",
    "    p.resetBasePositionAndOrientation(pandaUid2, [1, 0, 0], [0, 0, 0, 1])\n",
    "    robot2 = eye_in_hand_robot(pandaUid2, initialJointPosition)\n",
    "\n",
    "    # Load Box\n",
    "    box = p.loadURDF(\"cube_small.urdf\", [0,0.5, 0.02])\n",
    "    for _ in range(240):\n",
    "        p.stepSimulation()\n",
    "        # width, height, rgbImg, depthImg, segImg = p.getCameraImage(640, 480)\n",
    "        # rgbImg = np.reshape(rgbImg, (height, width, 4))\n",
    "        # out.write(cv2.cvtColor(rgbImg, cv2.COLOR_RGBA2BGR))\n",
    "        # time.sleep(1./240.)\n",
    "\n",
    "    # Enable collision detection between robot and box\n",
    "    p.setCollisionFilterPair(robot1.robot_id, box, -1, -1, 1)\n",
    "    p.setCollisionFilterPair(robot2.robot_id, box, -1, -1, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set up video writer # uncomment necessory lines to record a video\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "# out = cv2.VideoWriter('output.mp4', fourcc, 30.0, (640, 480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pybenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value: 0.00813641192960446\n",
      "z value at maximum: 0.15003061403086104\n"
     ]
    }
   ],
   "source": [
    "# Optimizing the z coordinate for hand over\n",
    "from scipy.optimize import minimize_scalar\n",
    "operate_ee(robot1,1)\n",
    "operate_ee(robot2,1)\n",
    "res = minimize_scalar(to_optimise, bounds=(0.15, 0.75), method='bounded')\n",
    "max_value = -1 * res.fun\n",
    "max_z = res.x\n",
    "\n",
    "print(f\"Maximum value: {max_value}\")\n",
    "print(f\"z value at maximum: {max_z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving the arms to a default position\n",
    "T0 = sm.SE3.Rt(np.array(sm.SO3.RPY([90,0,0],unit= 'deg')),np.array([0,0.5,0.5]))\n",
    "T7 = sm.SE3.Rt(np.array(sm.SO3.RPY([0,0,0],unit= 'deg')),np.array([1,0.5,0.5]))\n",
    "\n",
    "move_ee(robot1,T0)\n",
    "move_ee(robot2,T7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving robot1 towards the cube\n",
    "T1 = sm.SE3.Rt(np.array(sm.SO3.RPY([90,0,0],unit= 'deg')),np.array([0,0.5,0.5]))\n",
    "T2 = sm.SE3.Rt(np.array(sm.SO3.RPY([90,0,0],unit= 'deg')),np.array([0,0.5,0.025]))\n",
    "trajectory =rtb.ctraj(T1,T2,20)\n",
    "move_traj_ee(robot1,trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grasping the cube\n",
    "operate_ee(robot1,0.017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the robots to the hand over position\n",
    "T3 = sm.SE3.Rt(np.array(sm.SO3.RPY([90,0,90],unit= 'deg')),np.array([0.5,0.5,max_z]))\n",
    "trajectory =rtb.ctraj(T2,T3,20)\n",
    "move_traj_ee(robot1,trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "T4 = sm.SE3.Rt(np.array(sm.SO3.RPY([0,-90,0],unit= 'deg')),np.array([0.6,0.5,max_z]))\n",
    "move_ee(robot2,T4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "operate_ee(robot2,1)\n",
    "T5 = sm.SE3.Rt(np.array(sm.SO3.RPY([0,-90,0],unit= 'deg')),np.array([0.5,0.5,max_z]))\n",
    "trajectory =rtb.ctraj(T4,T5,20)\n",
    "move_traj_ee(robot2,trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hand over\n",
    "operate_ee(robot2,0.017)\n",
    "operate_ee(robot1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placing the cube at the end position\n",
    "T6 = sm.SE3.Rt(np.array(sm.SO3.RPY([0,0,0],unit= 'deg')),np.array([1,0.5,0.025]))\n",
    "trajectory =rtb.ctraj(T5,T6,20)\n",
    "move_traj_ee(robot2,trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "operate_ee(robot2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving the arms at the default position\n",
    "T7 = sm.SE3.Rt(np.array(sm.SO3.RPY([0,0,0],unit= 'deg')),np.array([1,0.5,0.5]))\n",
    "move_ee(robot2,T7)\n",
    "move_ee(robot1,T0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Release video writer\n",
    "# out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cv2.destroyAllWindows()\n",
    "    p.disconnect()\n",
    "except:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
